from __future__ import annotations

from pathlib import Path
from typing import Any, List, Tuple
import sys
from contextlib import nullcontext

import numpy as np
from rich.console import Console

from h5ad.formats.common import _get_encoding_type, _resolve
from h5ad.formats.validate import validate_dimensions
from h5ad.storage import create_dataset, is_dataset, is_group, is_zarr_group
from h5ad.util.path import norm_path


def _read_mtx(
    input_file: Path,
) -> Tuple[List[Tuple[int, int, float]], Tuple[int, int], int]:
    with open(input_file, "r", encoding="utf-8") as fh:
        header = fh.readline()
        if not header.startswith("%%MatrixMarket"):
            raise ValueError("Invalid MTX file: missing MatrixMarket header.")

        parts = header.lower().split()
        field = "real"
        for p in parts:
            if p in ("real", "integer", "complex", "pattern"):
                field = p
                break

        line = fh.readline()
        while line.startswith("%"):
            line = fh.readline()

        dims = line.split()
        n_rows, n_cols, nnz = int(dims[0]), int(dims[1]), int(dims[2])

        entries = []
        for _ in range(nnz):
            parts = fh.readline().split()
            r, c = int(parts[0]) - 1, int(parts[1]) - 1
            if field == "pattern":
                v = 1.0
            else:
                v = float(parts[2])
            entries.append((r, c, v))

    return entries, (n_rows, n_cols), nnz


def _create_csr_from_entries(
    entries: List[Tuple[int, int, float]], shape: Tuple[int, int]
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    n_rows, _ = shape
    entries.sort(key=lambda x: (x[0], x[1]))

    data = np.array([e[2] for e in entries], dtype=np.float32)
    indices = np.array([e[1] for e in entries], dtype=np.int32)

    indptr = np.zeros(n_rows + 1, dtype=np.int32)
    for r, _, _ in entries:
        indptr[r + 1] += 1
    indptr = np.cumsum(indptr)

    return data, indices, indptr


def export_mtx(
    root: Any,
    obj: str,
    out: Path | None,
    head: int | None,
    chunk_elements: int,
    in_memory: bool,
    console: Console,
) -> None:
    h5obj = _resolve(root, obj)
    if not is_group(h5obj):
        raise ValueError("MTX export requires a CSR/CSC matrix group (not a dataset).")

    enc = _get_encoding_type(h5obj)
    if enc not in ("csr_matrix", "csc_matrix"):
        raise ValueError(
            f"Target group encoding-type is {enc!r}; expected 'csr_matrix' or 'csc_matrix'."
        )

    data = h5obj.get("data")
    indices = h5obj.get("indices")
    indptr = h5obj.get("indptr")
    if not (is_dataset(data) and is_dataset(indices) and is_dataset(indptr)):
        raise ValueError(
            "Sparse matrix group must contain datasets: data, indices, indptr"
        )

    shape = h5obj.attrs.get("shape", None)
    if shape is None:
        raise ValueError("Sparse matrix group is missing required 'shape' attribute.")
    n_rows, n_cols = (int(shape[0]), int(shape[1]))

    field = "real" if np.issubdtype(data.dtype, np.floating) else "integer"

    indptr_arr = np.asarray(indptr[...], dtype=np.int64)
    nnz_ptr = int(indptr_arr[-1]) if indptr_arr.size else 0
    nnz_data = int(data.shape[0])
    nnz_idx = int(indices.shape[0])

    if not (nnz_ptr == nnz_data == nnz_idx):
        raise ValueError(
            f"Sparse matrix data inconsistency: indptr implies {nnz_ptr} nonzeros, "
            f"but data has {nnz_data} and indices has {nnz_idx}."
        )

    nnz = nnz_data
    major_step = max(1, int(chunk_elements))
    if head is not None and head > 0:
        nnz = min(nnz_data, head)

    if out is None or str(out) == "-":
        out_fh = sys.stdout
    else:
        out.parent.mkdir(parents=True, exist_ok=True)
        out_fh = open(out, "w", encoding="utf-8", newline="\n")

    use_status = out_fh is not sys.stdout
    status_ctx = (
        console.status(f"[magenta]Exporting {obj} to {out}...[/]")
        if use_status
        else nullcontext()
    )
    try:
        out_fh.write(f"%%MatrixMarket matrix coordinate {field} general\n")
        out_fh.write("% generated by h5ad-cli\n")
        if head is not None and head > 0:
            out_fh.write(f"% output limited to first {nnz}/{nnz_data} nonzero entries\n")
        out_fh.write(f"{n_rows} {n_cols} {nnz}\n")

        if in_memory:
            with status_ctx as status:
                if use_status and status:
                    status.update(
                        f"[magenta]Loading entire matrix {obj} into memory...[/]"
                    )
                data_arr = np.asarray(data[...])
                indices_arr = np.asarray(indices[...], dtype=np.int64)
                counts = np.diff(indptr_arr)
                if int(counts.sum()) != nnz_data:
                    raise ValueError(
                        "Sparse matrix indptr does not match data/indices length."
                    )

                if enc == "csr_matrix":
                    major_idx = np.repeat(np.arange(n_rows, dtype=np.int64), counts)
                    row_idx = major_idx
                    col_idx = indices_arr
                else:
                    major_idx = np.repeat(np.arange(n_cols, dtype=np.int64), counts)
                    row_idx = indices_arr
                    col_idx = major_idx

                if head is not None and head > 0:
                    row_idx = row_idx[:nnz]
                    col_idx = col_idx[:nnz]
                    data_arr = data_arr[:nnz]

                data_fmt = "%.18g" if field == "real" else "%d"
                coords = np.column_stack((row_idx + 1, col_idx + 1, data_arr))
                if use_status and status:
                    status.update(f"[magenta]Saving {nnz} entries to {out}...[/]")
                np.savetxt(out_fh, coords, fmt=["%d", "%d", data_fmt], newline="\n")
        else:
            major = n_rows if enc == "csr_matrix" else n_cols
            max_lines = head if head is not None and head > 0 else None
            written = 0
            with status_ctx as status:
                for major_start in range(0, major, major_step):
                    major_end = min(major_start + major_step, major)
                    if use_status and status:
                        status.update(
                            f"[magenta]Exporting {obj}: {major_start+1}-{major_end} of {major}...[/]"
                        )
                    for major_i in range(major_start, major_end):
                        start = min(int(indptr_arr[major_i]), nnz_data)
                        end = min(int(indptr_arr[major_i + 1]), nnz_data)
                        if end <= start:
                            continue
                        idx = np.asarray(indices[start:end], dtype=np.int64)
                        vals = np.asarray(data[start:end])
                        m = min(len(idx), len(vals))
                        if m == 0:
                            raise ValueError("Sparse matrix chunk has zero length.")
                        if max_lines is not None:
                            remaining = max_lines - written
                            if remaining <= 0:
                                break
                            if m > remaining:
                                m = remaining
                        idx = idx[:m]
                        vals = vals[:m]
                        idx_list = idx.tolist()
                        vals_list = vals.tolist()
                        if enc == "csr_matrix":
                            r = major_i + 1
                            lines = [
                                f"{r} {c + 1} {v}\n"
                                for c, v in zip(idx_list, vals_list)
                            ]
                        else:
                            c = major_i + 1
                            lines = [
                                f"{r + 1} {c} {v}\n"
                                for r, v in zip(idx_list, vals_list)
                            ]
                        out_fh.write("".join(lines))
                        written += m
                        if max_lines is not None and written >= max_lines:
                            break
                    if max_lines is not None and written >= max_lines:
                        break
    finally:
        if out_fh is not sys.stdout:
            out_fh.close()
    if out_fh is not sys.stdout:
        console.print(f"[green]Wrote[/] {out}")


def import_mtx(
    root: Any,
    obj: str,
    input_file: Path,
    console: Console,
) -> None:
    obj = norm_path(obj)
    entries, shape, nnz = _read_mtx(input_file)
    data, indices, indptr = _create_csr_from_entries(entries, shape)

    validate_dimensions(root, obj, shape, console)

    parts = obj.split("/")
    parent = root
    for part in parts[:-1]:
        parent = parent[part] if part in parent else parent.create_group(part)
    name = parts[-1]

    if name in parent:
        del parent[name]

    group = parent.create_group(name)
    group.attrs["encoding-type"] = "csr_matrix"
    group.attrs["encoding-version"] = "0.1.0"
    if is_zarr_group(group):
        group.attrs["shape"] = list(shape)
    else:
        group.attrs["shape"] = np.array(shape, dtype=np.int64)

    create_dataset(group, "data", data=data)
    create_dataset(group, "indices", data=indices)
    create_dataset(group, "indptr", data=indptr)

    console.print(
        f"[green]Imported[/] {shape[0]}Ã—{shape[1]} sparse matrix ({nnz} non-zero) into '{obj}'"
    )
